#' @title Fit a Normal mixture model on the data using EM Algorithm
#' @export
#' @description Fit a normal mixture that maximizes the log likelihood of the weights
#' of each method using the Expectation-Maximization (EM) algorithm.
#' @param Y The true Y values for fitting
#' @param y_hat The predictions output from a model. Note that this is passed as an $NxK$ matrix, where $K$ is the number of predictors.
#' @param tol Convergence tolerance for the EM algorithm. Default is 1e-6.
#' @param max_iter Maximum number of iterations for the EM algorithm. Default is 1000.
#' @examples
#' \dontrun{
#' # Make three small test models for mixing
#' y_hat1 <- rnorm(1000, 3, 1)
#' y_hat2 <- rnorm(1000, 3, 1.5)
#' y_hat3 <- rnorm(1000, 3, 0.5)
#'
#' y_hat <- cbind(y_hat1, y_hat2, y_hat3)
#'
#' w <- c(0.5, 0.2, 0.3)
#' y <- (y_hat %*% w + rnorm(1000))[, 1]
#'
#' model_aggregator <- fitAggregationFunction(y_hat, y)
#' predict(model_aggregator, y_hat, alpha=0.05)
#' }
```{r}
fitAggregationFunction <- function(y_hat, Y, tol = 1e-6, max_iter = 1000) {
    n <- nrow(y_hat)
    k <- ncol(y_hat)
    
    # Initialize weights (betas) uniformly
    betas <- rep(1 / k, k)
    
    # EM algorithm
    log_likelihood <- function(beta_vect) {
        y_hat_mu <- y_hat %*% beta_vect
        sigma <- sqrt(mean((Y - y_hat_mu)^2))
        -sum(dnorm(Y, mean = y_hat_mu, sd = sigma, log = TRUE))
    }
    
    # Initialize parameters
    sigma <- sqrt(mean((Y - y_hat %*% betas)^2))
    iter <- 0
    diff <- Inf
    
    while (iter < max_iter && diff > tol) {
        # E-step: Compute responsibilities
        y_hat_mu <- y_hat %*% betas
        responsibilities <- sapply(1:k, function(j) {
            beta_temp <- rep(0, k)
            beta_temp[j] <- 1
            exp(-log_likelihood(beta_temp))
        })
        responsibilities <- responsibilities / rowSums(responsibilities)
        
        # M-step: Update betas
        betas_new <- colMeans(responsibilities)
        sigma_new <- sqrt(mean((Y - y_hat %*% betas_new)^2))
        
        # Check for convergence
        diff <- sum(abs(betas - betas_new))
        betas <- betas_new
        sigma <- sigma_new
        iter <- iter + 1
    }
    
    if (iter == max_iter) {
        warning("EM algorithm did not converge within the maximum number of iterations.")
    }
    
    # Finalize and return the results
    structure(
        list(
            betas = betas,
            sigma = sigma,
            log_likelihood = -log_likelihood(betas),
            iterations = iter
        ),
        class = c("ModelAggregator", "list")
    )
}

#' @export
predict.ModelAggregator <- function(obj, y_hat, alpha = 0.05, n_trials = 1000, ...) {
    betas <- obj$betas
    sigma <- obj$sigma
    mus <- y_hat %*% betas
    
    # Generate prediction intervals
    predicted_dists <- matrix(
        rnorm(n_trials * nrow(y_hat), mean = rep(mus, each = n_trials), sd = sigma),
        nrow = nrow(y_hat),
        byrow = FALSE
    )
    pi <- t(apply(predicted_dists, 1, function(preds) {
        quantile(preds, probs = c(alpha / 2, 1 - alpha / 2))
    }))
    cbind(
        'mean' = rowMeans(predicted_dists),
        'lower' = pi[, 1],
        'upper' = pi[, 2]
    )
}
```